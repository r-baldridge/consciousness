# Form 13: Integrated Information Theory

## Comprehensive Research Documentation

**Document Version:** 1.0
**Created:** 2026-01-29
**Status:** Research Foundation Complete
**Domain:** Mathematical Consciousness Theory / Neuroscience of Consciousness

---

## Table of Contents

1. [Scientific Foundation](#1-scientific-foundation)
2. [Key Research Areas](#2-key-research-areas)
3. [Major Theories and Models](#3-major-theories-and-models)
4. [Experimental Paradigms](#4-experimental-paradigms)
5. [Philosophical Implications](#5-philosophical-implications)
6. [Cross-Form Connections](#6-cross-form-connections)

---

## 1. Scientific Foundation

### 1.1 Key Researchers and Their Contributions

**Giulio Tononi** (University of Wisconsin-Madison) is the primary architect of Integrated Information Theory, having developed the framework from its initial formulation through successive major revisions. Tononi's central insight is that consciousness corresponds to integrated information -- the amount of information generated by a system above and beyond what is generated by its parts independently. His foundational paper, "An information integration theory of consciousness" (2004), established the core axioms that would evolve into a comprehensive mathematical theory of consciousness. Tononi introduced the measure Phi (capital Greek letter) as a quantification of integrated information, proposing that any system with Phi greater than zero possesses some degree of consciousness. His subsequent work refined the mathematical formalism through IIT 2.0 (2008-2012), IIT 3.0 (Oizumi, Albantakis, & Tononi, 2014), and the most recent IIT 4.0 (Albantakis, Barbosa, et al., 2023), each iteration addressing limitations of its predecessor while maintaining the theory's foundational commitments.

**Christof Koch** (Allen Institute for Brain Science) has been Tononi's most prominent scientific partner in developing IIT's empirical program. Koch, previously a long-time collaborator of Francis Crick in the search for the neural correlates of consciousness (NCC), brought decades of neuroscience expertise to IIT's empirical grounding. Koch and Tononi co-authored several landmark papers connecting IIT to neural data, including work on the posterior cortical "hot zone" hypothesis and the relationship between information integration and thalamocortical connectivity. Koch's 2012 book "Consciousness: Confessions of a Romantic Reductionist" brought IIT to a broader scientific audience.

**Larissa Albantakis** (University of Wisconsin-Madison) has been instrumental in the mathematical formalization of IIT, particularly in developing IIT 3.0 and 4.0. Albantakis co-led the major 2023 paper "Integrated Information Theory (IIT) 4.0: Formulating the Properties of Phenomenal Existence in Physical Terms" published in PLOS Computational Biology, which introduced significant refinements to the mathematical framework. Her contributions include clarifying the relationship between causal structures and phenomenal properties and developing more rigorous computational methods for evaluating IIT's postulates.

**David Balduzzi** contributed foundational mathematical work, co-authoring with Tononi the 2008 paper "Integrated information in discrete dynamical systems: Motivation and theoretical framework," which formalized the computational framework for IIT in discrete systems.

**Masafumi Oizumi** co-authored the definitive IIT 3.0 paper (2014), "From the phenomenology to the mechanisms of consciousness: Integrated Information Theory 3.0," which restructured the theory around five axioms (Intrinsic Existence, Composition, Information, Integration, Exclusion) and their corresponding postulates.

**William Mayner** and colleagues developed PyPhi (2018), the first complete computational implementation of IIT 3.0, enabling researchers to compute Phi for small discrete systems and serving as a reference implementation for the theory's mathematical formalism.

**Marcello Massimini** (University of Milan) developed the Perturbational Complexity Index (PCI), the most clinically successful empirical measure inspired by IIT. Massimini's TMS-EEG paradigm, first published by Casali et al. (2013) in Science Translational Medicine, provides a practical surrogate for Phi that can be measured in real brains and has been validated across wake, sleep, anesthesia, and disorders of consciousness.

### 1.2 Major Discoveries

The development of PCI by Casali, Gosseries, Rosanova, Boly, Sarasso, and Massimini (2013) stands as IIT's most significant empirical achievement. PCI measures the algorithmic complexity of the brain's response to a transcranial magnetic stimulation (TMS) pulse, yielding a single number that reliably distinguishes conscious from unconscious states. Studies have shown PCI values above approximately 0.31 in conscious waking, dreaming, and locked-in syndrome, while values fall below this threshold during dreamless sleep, general anesthesia, and vegetative states. This measure has been validated in over 200 patients with disorders of consciousness and has been shown to correctly classify consciousness levels with high sensitivity and specificity.

Rosanova et al. (2012) demonstrated the breakdown of cortical effective connectivity during unconsciousness, showing that TMS perturbations produce stereotyped, local responses during NREM sleep and anesthesia rather than the complex, differentiated responses seen during wakefulness. This finding directly supports IIT's prediction that consciousness requires both differentiation (many possible states) and integration (unified processing).

Sarasso et al. (2015) extended PCI to sleep states, demonstrating that PCI tracks not only the difference between waking and NREM sleep but also correlates with the presence or absence of dream reports during NREM sleep, providing evidence that the measure captures phenomenal consciousness rather than merely behavioral responsiveness.

### 1.3 Current Debates

The most prominent critique of IIT is the "unfolding argument" advanced by Doerig, Schurger, Hess, and colleagues (2019), published in Consciousness and Cognition. This argument claims that for any system with a given causal structure (and thus a given Phi value), there exists a functionally equivalent system with a different causal structure (and thus a different Phi value) that produces identical input-output behavior. If IIT assigns different consciousness levels to functionally equivalent systems, the argument goes, then IIT's predictions are empirically unfalsifiable.

The IIT community, led by Tononi and Albantakis, has responded by arguing that the unfolding argument mischaracterizes IIT's commitments. IIT does not claim that consciousness is determined by input-output function; it explicitly claims that consciousness is determined by intrinsic causal structure. The fact that two systems with different intrinsic structures but identical external behavior would have different Phi values is, according to IIT proponents, a feature rather than a bug -- it reflects IIT's commitment to causal structure as the basis of consciousness.

A second major debate concerns IIT's panpsychist implications. Because IIT assigns some degree of integrated information to any system with even minimal causal structure, the theory implies that simple physical systems (such as thermostats or logic gates) have vanishingly small but nonzero consciousness. This consequence has been embraced by some philosophers (notably Philip Goff) as a strength of the theory and rejected by others (notably Daniel Dennett and Patricia Churchland) as a reductio ad absurdum.

The computational intractability problem remains a persistent practical challenge. Exact Phi computation scales super-exponentially with system size, making it infeasible for systems larger than approximately 10-12 elements with current algorithms. This has motivated the development of approximation methods, including the Gaussian approximation (Oizumi et al., 2016), geometric approaches, and the PCI surrogate measure.

The Templeton World Charity Foundation adversarial collaboration, initiated in 2019, pitted IIT against Global Neuronal Workspace theory in pre-registered experiments. Initial results reported by the Cogitate Consortium in 2023 provided mixed evidence, with neither theory fully confirmed or refuted, driving continued refinement of both frameworks.

---

## 2. Key Research Areas

### 2.1 Mathematical Formalization of Consciousness

IIT's mathematical framework has undergone four major revisions. The current version, IIT 4.0 (Albantakis et al., 2023), defines consciousness in terms of a system's intrinsic cause-effect structure. The theory begins with five phenomenological axioms describing properties that are self-evidently true of every experience: Intrinsic Existence (experience exists from its own intrinsic perspective), Composition (experience is structured), Information (experience is specific), Integration (experience is unified), and Exclusion (experience is definite). Each axiom maps to a corresponding postulate describing the physical substrate's required properties. The central quantity, Phi (system integrated information), is computed as the minimum information partition -- the least informative way to divide the system into independent parts. A system's "conceptual structure" (its complete cause-effect structure in IIT terminology) specifies the quality of the corresponding experience, while Phi specifies its quantity or level.

### 2.2 Empirical Measurement and Clinical Assessment

The clinical program built around PCI has advanced rapidly since its introduction. Casarotto et al. (2016) demonstrated that different anesthetic agents (propofol, xenon, midazolam, ketamine) reduce PCI in dose-dependent fashion, with the exception of ketamine, which preserves PCI at anesthetic doses -- consistent with the rich subjective experiences (dissociative states) reported during ketamine anesthesia. Bodart et al. (2017) showed that PCI can predict recovery of consciousness in vegetative and minimally conscious patients, with higher PCI values at diagnosis associated with better long-term outcomes. Comolatti et al. (2019) refined the PCI methodology with a normalized version (PCIst) that is more robust across different stimulation sites and recording conditions.

### 2.3 Computational Implementation and Approximation

Given the intractability of exact Phi computation, significant effort has been directed toward developing efficient approximations. The PyPhi software library (Mayner et al., 2018) provides exact IIT 3.0 computation for small systems but cannot scale beyond approximately 12 nodes. Barrett and Seth (2011) proposed a practical integrated information measure based on the mutual information between a system's past and future states across its minimum information partition. Mediano et al. (2019, 2022) developed partial information decomposition approaches that capture aspects of information integration more efficiently. The Gaussian approximation method (Oizumi et al., 2016) allows Phi computation for continuous systems under Gaussian assumptions, enabling application to neural time series data.

### 2.4 Cross-Species and Evolutionary Studies

IIT makes specific predictions about the distribution of consciousness across species, based on the integration architecture of different nervous systems. Birch, Schnell, and Clayton (2020) applied IIT-inspired reasoning to evaluate consciousness across the animal kingdom, arguing that the theory predicts consciousness in any organism with sufficiently integrated neural architecture. Nieder et al. (2020) demonstrated neural correlates consistent with IIT predictions in corvid birds, suggesting that despite lacking a neocortex, corvids possess pallial circuits with high integration capacity that may support consciousness.

---

## 3. Major Theories and Models

### 3.1 IIT 3.0 (Oizumi, Albantakis, & Tononi, 2014)

IIT 3.0 reorganized the theory around five axioms and five corresponding postulates. The axioms describe essential properties of phenomenal experience, while the postulates translate these into requirements for physical substrates. The theory identifies a system's "conceptual structure" -- the set of all its "concepts" (mechanisms with integrated cause-effect power) -- as the mathematical object that specifies the quality of the corresponding experience. The maximum of integrated conceptual information, called "big Phi," specifies the level of consciousness. The Exclusion postulate introduces a principle of parsimony: consciousness is associated with the set of elements that forms the maximum of integrated information, excluding both supersets and subsets. This determines the physical boundaries of the conscious "complex."

### 3.2 IIT 4.0 (Albantakis, Barbosa, et al., 2023)

IIT 4.0 introduced several important refinements. The formalization was tightened to ensure that intrinsic information is computed using intrinsic differences rather than observer-dependent measures like Kullback-Leibler divergence. The notion of "intrinsic information" was replaced with a new measure based on the system's own "informativeness" and "selectivity." The 4.0 formulation also clarified the relationship between the theory's mathematical formalism and its phenomenological commitments, providing more explicit accounts of how spatial, temporal, and qualitative aspects of experience map onto causal structures.

### 3.3 The Perturbational Complexity Index (PCI)

While not a theory per se, PCI represents IIT's most successful translation into empirical neuroscience. PCI is not a direct measure of Phi but rather a surrogate that captures the intuition behind IIT: a conscious brain should respond to perturbation with complex, differentiated, and integrated activity. PCI is computed as the Lempel-Ziv complexity of the spatiotemporal pattern of cortical activation evoked by a TMS pulse, normalized by the source entropy. The measure combines differentiation (the response must be complex) and integration (the response must be widespread, reflecting communication across brain areas).

### 3.4 Causal Emergence Theory (Hoel, Albantakis, & Tononi, 2013)

A related theoretical framework developed within the IIT program is Causal Emergence theory, which proposes that higher-level descriptions of a system can carry more causal information than lower-level descriptions. Hoel et al. demonstrated that coarse-graining a system can sometimes increase its effective information, suggesting that the "right" level of description for understanding consciousness may not always be the most fundamental physical level. This work has implications for the debate about whether consciousness should be understood at the neural, network, or cognitive level.

---

## 4. Experimental Paradigms

### 4.1 TMS-EEG Perturbational Paradigm

The TMS-EEG paradigm is the primary experimental tool for testing IIT-inspired hypotheses. A TMS pulse is delivered to a cortical region while high-density EEG records the brain's response. In conscious states (wakefulness, REM sleep, ketamine anesthesia, locked-in syndrome), the response is complex, differentiated, and widespread. In unconscious states (NREM sleep, propofol/xenon anesthesia, vegetative state), the response is either absent, stereotyped, or locally confined. Casali et al. (2013) demonstrated that PCI computed from these responses reliably classifies consciousness levels. The paradigm has been replicated across multiple laboratories and clinical settings worldwide.

### 4.2 Sleep Studies

Sleep provides a natural model for studying the transition between conscious and unconscious states. Sarasso et al. (2015) used TMS-EEG during sleep to show that PCI decreases during NREM sleep but is restored during REM sleep. Critically, within NREM sleep, PCI was higher when subjects reported dreaming upon awakening than when they reported no experience, suggesting PCI tracks phenomenal consciousness rather than behavioral responsiveness. Siclari et al. (2017) extended this work using content analysis of dream reports correlated with high-density EEG, finding that dreaming during NREM sleep is associated with posterior cortical activation patterns consistent with IIT predictions.

### 4.3 Anesthesia Studies

Studies of anesthesia-induced unconsciousness provide controlled models for investigating IIT predictions. Ferrarelli et al. (2010) showed that the anesthetic midazolam abolishes the complex cortical response to TMS, replacing it with a stereotyped, locally confined wave. Sarasso et al. (2015) and Casarotto et al. (2016) systematically compared multiple anesthetic agents, demonstrating that agents producing dreamlike experiences (ketamine) preserve cortical complexity while agents producing oblivion (propofol, xenon) abolish it. These results support IIT's prediction that the level of consciousness corresponds to the capacity for differentiated and integrated neural responses.

### 4.4 Disorders of Consciousness Studies

Clinical studies of patients with disorders of consciousness provide the most medically significant application of IIT-inspired measures. Rosanova et al. (2012) demonstrated that PCI can distinguish vegetative state from minimally conscious state, a distinction that is clinically critical but often difficult to make at the bedside. Casali et al. (2013) showed that PCI correctly classified consciousness levels in 48 of 48 subjects across various states (wake, sleep, anesthesia, brain injury). Bodart et al. (2017) demonstrated PCI's prognostic value, with higher PCI at diagnosis predicting better outcomes months to years later. Luppi et al. (2019) extended this work to show that multimodal neuroimaging combined with IIT-inspired measures can improve diagnostic accuracy.

### 4.5 Split-Brain Studies

IIT makes a distinctive prediction about split-brain patients (who have had their corpus callosum severed): each hemisphere should form an independent Phi-complex and thus support an independent conscious experience. This prediction contrasts with Global Workspace Theory, which emphasizes the role of long-range connections in sustaining consciousness. While direct PCI measurements in split-brain patients are limited, existing behavioral and neuroimaging evidence is consistent with the IIT prediction of two separate conscious fields in split-brain patients, each with reduced integration compared to the intact brain.

---

## 5. Philosophical Implications

### 5.1 IIT and the Hard Problem

IIT takes a distinctive approach to the "hard problem" of consciousness articulated by David Chalmers (1995). Rather than attempting to explain why physical processes give rise to experience, IIT starts from the properties of experience itself (the axioms) and asks what physical structures must exist for those properties to be realized (the postulates). This "phenomenology-first" approach inverts the standard scientific strategy of starting with physical processes and attempting to derive experience. IIT proponents argue that this approach dissolves rather than solves the hard problem, by identifying consciousness with integrated information rather than trying to explain how one gives rise to the other.

### 5.2 Panpsychism and Consciousness Distribution

IIT's mathematical framework implies that any system with nonzero integrated information has some degree of consciousness. This consequence aligns with philosophical panpsychism -- the view that consciousness is a fundamental and ubiquitous feature of reality. Tononi and Koch (2015) have explicitly endorsed this implication, arguing that IIT provides a principled, non-mystical version of panpsychism grounded in information theory and causal analysis. Critics, including Daniel Dennett and Massimo Pigliucci, have argued that this consequence is implausible and that attributing consciousness to simple systems like photodiodes or logic gates stretches the concept of consciousness beyond usefulness.

### 5.3 The Exclusion Postulate and Personal Identity

IIT's Exclusion postulate has profound implications for personal identity and the boundaries of consciousness. The postulate states that consciousness is associated with the maximum of integrated information -- only one complex at one spatiotemporal grain is conscious, excluding all overlapping alternatives. This means that at any moment, there is a definite fact about which set of physical elements constitutes "your" conscious experience, and this set cannot overlap with or be included in another conscious complex. This has implications for debates about split-brain consciousness, fusion and fission thought experiments, and the possibility of group consciousness.

### 5.4 IIT and Artificial Consciousness

IIT makes specific predictions about when artificial systems would be conscious. The theory implies that current digital computers, despite their enormous computational power, have very low Phi because their architecture is highly decomposable -- the state of each transistor can be predicted independently from the states of other transistors through the system's gate structure. This prediction challenges the common assumption that sufficiently complex computation automatically yields consciousness. IIT suggests that consciousness depends on the intrinsic causal architecture of a system, not on what it computes or how it behaves, leading to the provocative claim that a perfect simulation of a conscious brain on a standard computer would not itself be conscious.

---

## 6. Cross-Form Connections

### 6.1 Connection to Form 14 (Global Workspace Theory)

IIT and GWT are often viewed as complementary rather than competing theories. IIT addresses what Tononi and Koch call "the quality problem" -- what determines the specific character of an experience -- through the geometry of conceptual structures. GWT addresses what Baars and Dehaene call "the access problem" -- what determines which information becomes globally available to cognitive systems. In a combined framework, IIT provides the substrate (integrated information complexes generate conscious content) while GWT provides the access mechanism (global broadcasting makes that content available for report, memory, and action). The Templeton adversarial collaboration has directly tested divergent predictions of the two theories, particularly regarding whether the NCC are primarily posterior-cortical (as IIT predicts) or frontoparietal (as GNW predicts).

### 6.2 Connection to Form 15 (Higher-Order Thought)

IIT and HOT theory offer deeply contrasting accounts of consciousness. HOT theory locates consciousness in the presence of higher-order representations -- thoughts about mental states. IIT locates consciousness in the intrinsic causal structure of a system, regardless of whether that system represents its own states. Nevertheless, there are points of contact: higher-order representations may contribute to information integration (adding meta-cognitive loops increases a system's Phi), and systems with high Phi may be more likely to generate higher-order representations. The empirical debate between the two frameworks centers on the role of the prefrontal cortex: HOT predicts prefrontal involvement in all conscious experience, while IIT associates phenomenal consciousness primarily with posterior cortical structures.

### 6.3 Connection to Form 16 (Predictive Coding)

Predictive coding frameworks and IIT intersect in their emphasis on hierarchical neural processing. Prediction error minimization requires integrating top-down predictions with bottom-up sensory signals across multiple cortical levels -- a process that necessarily involves information integration in the IIT sense. Hohwy (2013) has argued that the free energy principle provides a process theory that could complement IIT's structural theory: the predictive hierarchy's dynamics determine how integrated information flows and transforms over time, while IIT's framework characterizes the level and quality of the resulting consciousness.

### 6.4 Connection to Form 17 (Recurrent Processing)

Victor Lamme's Recurrent Processing Theory shares with IIT the emphasis on the importance of feedback connections for consciousness. Lamme (2006) argued that feedforward processing is unconscious and that recurrent (feedback) processing is necessary for consciousness. IIT provides a quantitative framework for this claim: feedforward architectures have low Phi because they are highly decomposable, while recurrent architectures have higher Phi because feedback connections create causal loops that resist decomposition. The temporal dynamics of recurrent processing (the transition from feedforward sweep to recurrent processing at ~150-200ms post-stimulus) correspond to the point at which cortical integration increases, as measured by PCI-like indices.

### 6.5 Connection to Form 18 (Primary Consciousness)

IIT provides the mathematical foundation for understanding primary consciousness -- the most basic level of felt, subjective experience. Gerald Edelman's notion of primary consciousness as arising from "reentrant signaling" in thalamocortical loops is naturally captured by IIT's framework: reentrant loops create integrated information that constitutes the basic "scene" of conscious experience. IIT's framework quantifies Edelman's intuition: the degree of primary consciousness corresponds to the Phi value of the thalamocortical system, while the content of primary consciousness corresponds to the system's conceptual structure. The transition from primary to higher-order consciousness (Edelman's distinction) corresponds in IIT terms to the inclusion of meta-cognitive circuits in the maximum Phi complex.

---

*This research document synthesizes the major scientific findings, theoretical frameworks, and ongoing debates surrounding Integrated Information Theory as the mathematical foundation for Form 13 of the 40-Form Consciousness architecture.*
