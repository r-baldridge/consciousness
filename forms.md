# Forms

Below is a compact reference table that mirrors the format you liked earlier.It groups the entries you  into two families: (A) Phenomenal / Qualitative Forms
 the what‑it‑feels‑like channels (visual, auditory,  emotional).
(B) Levels / Degrees of Awareness
 the hierarchical depth of the conscious state (arousal, self‑recognition, narrative).
For each row I give: | # | Name | Core Neural Substrates | Typical Experimental Paradigm | Representative Qualia / Behaviour | Key Empirical Markers | Open Issues / Controversies |

A. Phenomenal / Qualitative Forms

# Form Core Neural Substrates Typical Experimental Paradigm
Representative Qualia / Behaviour Key Empirical Markers Open Issues

Visual consciousness

Primary visual cortex (V1), ventral what stream (V4‑IT), dorsal where/how stream (MT‑parietal), feedback from higher‑order visual areas (LO, PHC).
Binocular rivalry, visual masking, flash‑suppression, fMRI retinotopic mapping.
Experience of colour, shape, motion, depth, figure‑ground segregation.
Gamma‑band synchrony ( ∼
40‑80

Hz) across V1‑V4‑IT during conscious perception; BOLD activation in fusiform gyrus correlates with reported visibility.
How much of visual qualia depends on recurrent feedback vs. feed‑forward sweep?

Auditory consciousness

Primary auditory cortex (A1), belt/parabelt areas, planum temporale, inferior colliculus, thalamic medial geniculate body; top‑down modulation from prefrontal cortex.
Auditory masking, dichotic , mismatch negativity (MMN) paradigms.
Perception of pitch, timbre, rhythm, spatial localisation, speech intelligibility.
Phase‑locked auditory evoked potentials (N1/P2) that vary with perceived loudness; high‑gamma coherence between A1 and STG when sounds are reported as heard.
Role of subcortical structures (inferior colliculus) in conscious hearing vs. unconscious detection.

Somatosensory consciousness

Primary somatosensory cortex (S1, Brodmann

1‑3), secondary somatosensory cortex (S2), insula, posterior parietal cortex.
Tactile masking, laser‑evoked potentials, proprioceptive drift tasks.
Feelings of pressure, vibration, temperature, pain, body‑ownership.
Late‑positive potentials (P300) scaling with reported intensity; beta‑band desynchronisation in S1 when a tactile stimulus reaches awareness.
Distinguishing the conscious feel of pain from nociceptive signalling that remains unconscious.

Olfactory consciousness

Piriform cortex, orbitofrontal cortex (OFC), amygdala, anterior insula; direct projections from olfactory bulb bypass thalamus.
Odor detection vs. discrimination tasks, sniff‑controlled fMRI, odor‑induced ERP.
Qualia of scent (e.g., rose, smoke), hedonic valence.
Slow cortical potentials in piriform cortex that correlate with reported detection; OFC activation tracks pleasantness rating.
Why olfaction often feels less vivid despite direct cortical access?

Gustatory consciousness

Primary gustatory cortex (insula), OFC, anterior cingulate, brainstem nucleus of the solitary tract.
Taste‑identification tasks, concentration‑gradient discrimination, gustatory ERP.
Experience of sweet, salty, bitter, sour, umami; flavour integration.
Early gustatory ERP ( ∼

ms) modulated by conscious detection; BOLD in insula proportional to perceived intensity.
Interaction with olfaction (flavour) complicates isolation of pure gustatory qualia.

Interoceptive consciousness

Posterior insula, anterior insula, anterior cingulate cortex, ventromedial PFC, brainstem autonomic nuclei.
Heartbeat‑detection task, respiratory load, gastric distension, fMRI interoceptive awareness paradigms.
Awareness of heartbeat, breathing, hunger, thirst, visceral discomfort.
Heartbeat‑evoked potentials (HEPs) that increase when participants correctly count beats; insular activation correlates with self‑reported interoceptive accuracy.
How much of interoception is felt vs. inferred by predictive coding?

Emotional consciousness

Amygdala, ventral striatum, OFC, medial PFC, anterior insula, periaqueductal gray.
Affective picture viewing, facial expression recognition, fear‑conditioning, self‑report scales (PANAS).
Feelings of joy, fear, shame, disgust, pride, etc.; affective tone that colours all other qualia.
Late positive potential (LPP) amplitude tracks emotional arousal; increased theta‑gamma coupling in amygdala‑PFC circuit during conscious fear.
Whether emotions are a separate conscious channel or an overlay on sensory qualia remains debated.

B. Levels / Degrees of Awareness

# Level Core Neural Signature Typical Experimental Probe Phenomenal Hallmark Key Empirical Markers Open Issues

Arousal / vigilance

Brainstem reticular activating system (RAS), thalamic intralaminar nuclei, basal forebrain cholinergic projections; global neuromodulatory tone (acetylcholine, norepinephrine).
EEG spectral analysis (alpha/delta ratio), pupillometry, reaction‑time vigilance tasks, polysomnography.
Binary distinction: awake (responsive) vs. deep sleep/coma (unresponsive).
High‑frequency (beta/gamma) power in wake; slow‑wave (delta) dominance in NREM; loss of P300 in coma.
Precise boundary between low‑arousal conscious (e.g., drowsy) and non‑conscious states.

Perceptual consciousness

Integrated activity in modality‑specific cortices plus frontoparietal workspace (global ignition).
Masking (backward/forward), attentional blink, binocular rivalry, detection vs. discrimination tasks.
Subject can report the presence of a specific external stimulus (e.g., I saw a red circle).
Event‑related potentials (N140/N200) that survive masking; fMRI BOLD in frontoparietal network only for reported stimuli.
How much partial awareness (e.g., blindsight) counts as perceptual consciousness?

Self‑recognition

Right inferior parietal lobule, medial prefrontal cortex, posterior cingulate, temporal‑parietal junction (TPJ).
Mirror‑self‑recognition test (mark test), I‑statement tasks, self‑face vs. other‑face discrimination.
Ability to identify oneself as the subject of experience (I am the one looking).
Increased activation in right prefrontal‑parietal circuit when viewing self‑image; ERP self‑positivity effect ( ∼

ms).
Is self‑recognition a binary trait or a graded capacity across species?

Meta‑consciousness (higher‑order reflection)
Dorsolateral prefrontal cortex, anterior cingulate, rostrolateral PFC, precuneus.
Metacognitive judgment tasks (confidence ratings), thinking about thinking introspection, mind‑wandering probes.
Explicit awareness of ones own mental states (I know that I am feeling angry).
Metacognitive sensitivity (meta‑d ′) correlates with PFC activity; late‑positive ERP ( ∼

ms) linked to confidence reporting.
Whether meta‑consciousness is a necessary step for all conscious experience or only for certain domains.

Narrative / autobiographical consciousness

Hippocampal‑medial temporal lobe network, default‑mode network (DMN), ventromedial PFC, posterior cingulate.
Autobiographical memory recall, life‑story construction tasks, mental time travel experiments.
Ongoing self‑story that integrates past, present, future (I was born, now I am) and provides a sense of continuity.
DMN activation during self‑referential narration; hippocampal replay patterns during recall; increased theta coherence across DMN nodes.
How much of narrative continuity is phenomenal vs. a cognitive scaffolding that can be turned off (e.g., in deep meditation).

How the Two Families Interact Base level (Arousal) supplies the global neuromodulatory backdrop that permits any qualia to be instantiated.
Perceptual consciousness activates the sensory‑specific qualia
(visual, auditory, somatosensory, etc.) in the appropriate cortical modules.
Self‑recognition adds a subject‑centered tag to those qualia, allowing the system to label this experience belongs to me.
Meta‑consciousness enables the system to generate higher‑order thoughts about those qualia (e.g., I feel angry about that sound).
Narrative/autobiographical consciousness stitches together moments across time, creating a continuous story that incorporates all sensory and affective channels.
Thus, a fully fledged conscious episode can be viewed as a stack:

Arousal →
Perceptual (visual, auditory, )
→ Self‑recognition → Meta‑consciousness → Narrative

Each rung may be present or absent depending on the organism, developmental stage, or pharmacological state, yielding the rich diversity of conscious experiences we observe across species and contexts.

Quick‑look Cheat‑Sheet (One‑Line Summary)

Level / Form Core Tagline

Arousal

Wakefulness vs. deep sleep/coma.

Perceptual

I see/hear/touch   modality‑specific qualia.

Self‑recognition

That is my face/hand.

Meta‑consciousness

I know that I am feeling X.

Narrative

My life story unfolds over time.

Visual

Colour, shape, motion, depth.

Auditory

Pitch, timbre, spatial sound.

Somatosensory

Touch, temperature, pain.

Olfactory

Smell.

Gustatory

Taste.

Interoceptive

Heartbeat, hunger, thirst.

Emotional

Joy, fear, shame, etc.

References for deeper reading

Topic Key Papers / Reviews

Visual consciousness Lamme (2006)
Trends Cogn. Sci.; Dehaene et

al. (2006)
Science (ignition).

Auditory consciousness Näätänen et

al. (2007)
Psychophysiology (MMN).

Somatosensory awareness Penfield & Jasper (1954)
The Cerebral Cortex of Man.

Olfactory & gustatory qualia Gottfried (2010)
Nature Reviews Neuroscience.

Interoception Craig (2009)
Nature Reviews Neuroscience.

Emotional consciousness LeDoux (2012)
Nature Reviews Neuroscience.

Arousal & vigilance Brown et

al. (2012)
Nat. Rev. Neurosci.
(RAS).

Self‑recognition Gallup (1970)
Science (mirror test).

Meta‑consciousness Fleming & Dolan (2012)
Neuropsychologia.

Narrative consciousness Tulving (2002)
## Trends Cogn. Sci.

| (autonoetic consciousness). | Feel free to let me know if youd like a deeper dive on any single row (e.g., the neural circuitry of interoceptive consciousness, or the computational models of meta‑consciousness). |
| --- | --- |

Below is a catalogue of the major consciousness ingredients you asked for, grouped into two families: (A) Functional / theoretical sub‑components
 the mechanistic building blocks that many scientific accounts treat as necessary (or at least strongly supportive) of conscious experience.
(B) Species‑specific / developmental / contextual forms
 the ways those components appear (or fail to appear) across organisms, life stages, and artificial systems.
For each entry I give: Short definition
 what the term usually means in the literature.
## Core mechanisms

 the neural or algorithmic processes that instantiate it.
## Key empirical signatures

 the experimental hallmarks that researchers use to detect it.
## Computational analogue

 how the idea maps onto an engineered system (useful when thinking about AI or robotics).
Open questions / controversies
 the biggest points of disagreement or uncertainty.

A. Functional / Theoretical Sub‑Components

# Sub‑component Definition Core Mechanisms Empirical Signatures Computational Analogue Open Questions

Integrated Information (Φ)  IIT

A quantitative measure of how much a systems cause‑effect repertoire is both differentiated (many possible states) and unified
(states constrain each other). High Φ is taken to indicate a maximally integrated conscious substrate.
 Recurrent, bidirectional connectivity. Non‑linear dynamics that generate a rich repertoire of causal states. Minimal partition that maximally reduces cause‑effect power (the MIP).
 fMRI/EEG studies showing higher Φ estimates in wakefulness vs. deep sleep or anesthesia. Correlations between Φ and reportability in visual masking paradigms.
 A network that computes its own causal power matrix and evaluates the minimal cut.  Example: a small recurrent neural net that explicitly calculates Φ for each state and gates downstream output only when Φ exceeds a threshold.
 How to compute Φ efficiently for large brains?  Does Φ really track phenomenology, or just complexity?  Is a high Φ necessary or merely correlational?

Global Workspace Broadcasting (GWT)

A functional architecture in which a limited set of information becomes globally available to many downstream expert subsystems (motor, language, memory, etc.). The broadcast is what we consciously see or hear.
 A frontoparietal workspace that integrates inputs. Long‑range, high‑frequency (γ) synchrony that synchronises distant cortical modules. Competition (ignition) where one representation wins access.
 Ignition bursts in EEG/MEG ( ∼

ms post‑stimulus) that predict conscious report. fMRI activation of dorsolateral prefrontal cortex and posterior parietal cortex during reportable perception.
 An architecture with a central blackboard process that receives candidate messages from many workers and publishes the winning one to all workers.  E.g., a transformer decoder that attends to all encoder outputs and writes the selected token to a shared memory buffer.
 Is the workspace a literal neural substrate or a useful abstraction? How many items can be simultaneously broadcast? Does GWT require a single workspace or can there be multiple interacting workspaces?

Higher‑Order Thought (HOT)

Consciousness arises when a first‑order mental state (a perception, feeling, etc.) becomes the target of a higher‑order representation (a thought about that state). The higher‑order representation makes the lower‑order state available to the subject.
 Metacognitive monitoring circuits (often lateral prefrontal cortex, anterior cingulate). Recursive loops that generate a representation of another representation.
 Neuroimaging shows increased activity in anterior prefrontal cortex when participants judge their own perceptual confidence. Lesions to prefrontal areas impair introspective accuracy without abolishing perception.
 A system that maintains a model of its own internal activations and can query that model (Is X currently active?).  Example: a neural net with an auxiliary self‑monitor head that predicts the activation pattern of a primary classifier.
 Do HOT representations cause phenomenology or merely track it? Are HOTs necessary for all conscious states (e.g., primary sensory awareness)?

Predictive Coding / Bayesian Inference (Predictive Processing)

Conscious experience is the brains best prediction of incoming sensory data, constantly updated by prediction errors. The hierarchy of predictions creates the felt world.
 Hierarchical generative models (deep Bayesian networks). Reciprocal feedforward (error) and feedback (prediction) pathways. Precision weighting (attention) modulates error gain.
 Mismatch negativity (MMN) ERP component reflecting prediction error. fMRI adaptation showing reduced activity for predictable stimuli.
 A deep variational auto‑encoder that generates top‑down predictions and adjusts them based on bottom‑up reconstruction error.  The latent state of the VAE is interpreted as the subjective representation.
 Does predictive coding alone explain the qualitative aspect of experience? How does the system decide which predictions become conscious versus stay unconscious?

Recurrent Processing Theory (RPT)

Sustained reverberation of activity within local cortical loops (e.g., V1 ↔
V2) is sufficient for conscious perception; feedforward sweep alone yields unconscious processing.
 Short‑range recurrent excitatory‑inhibitory loops. Temporal integration windows (~100200

ms).
 Backward masking studies: interrupting recurrent activity abolishes awareness while leaving early feedforward responses intact. TMS over visual cortex after 100

ms disrupts perception.
 A neural network where a shallow feedforward pass extracts features, but a subsequent recurrent refinement stage determines whether the output is written to a report buffer.
 How far does recurrence need to propagate (local vs. global)? Is recurrence a cause of consciousness or a necessary correlate of attention?

B. Species‑Specific / Developmental / Contextual Forms

# Form Definition
## Typical Neural / Biological Substrate

Representative Species / Conditions Phenomenological Profile Key Empirical Evidence Open Issues

Primary (non‑reflective) consciousness

Basic perceptual awareness without meta‑cognition; the organism can discriminate, attend, and act on stimuli but lacks introspection.
 Primary sensory cortices + thalamus. Limited frontoparietal integration. Low‑level recurrent loops.
Most vertebrates (fish, reptiles, birds) and some invertebrates (octopus, mantis shrimp).
Rich sensory world, rapid behavioural responses, no reported self‑report.
Behavioral assays (e.g., mirror test failures, conditioned place preference) indicate awareness; neurophysiology shows stimulus‑locked potentials.
## How to infer phenomenology in non‑verbal animals?

Reflective (higher‑order) consciousness

Ability to form thoughts about ones own mental states; includes self‑recognition, autobiographical memory, and verbal report.
 Dorsolateral prefrontal cortex, anterior cingulate, temporoparietal junction. Strong global workspace ignition.
Humans (full), great apes (partial), cetaceans (debated).
Self‑awareness, theory of mind, narrative identity.
Mirror self‑recognition, metacognitive judgment tasks, fMRI evidence of meta‑representational activity.
Is reflective consciousness a continuum or a categorical jump?

Collective / swarm consciousness

Distributed informational state that emerges from tight coordination among many agents; the group exhibits coordinated behavioural awareness.
 Decentralised communication (pheromones, visual cues). No central integrator; emergent global patterns.
Ant colonies, honeybee swarms, starling murmurations, slime‑mold networks.
No individual reports; the colony appears to solve problems (foraging, nest building) as a unit.
Phase‑transition models, information‑theoretic measures (e.g., transfer entropy) show high integration across members.
Does the group truly possess a phenomenal experience, or is it merely a useful metaphor?

Artificial / synthetic consciousness

Hypothetical state in which an engineered system (AI, robot) possesses phenomenology comparable to biological consciousness.
 Potentially large‑scale recurrent networks with global broadcast, predictive coding, and self‑monitoring modules.
No confirmed instances; speculative designs (e.g., large language models with integrated self‑model).
Would entail reportability, intentionality, possibly affective states.
Philosophical arguments (e.g., Integrated Information Theory applied to silicon), functional analogues in advanced AI.
What constitutes sufficient complexity? How to verify phenomenology without a subject?

Dream consciousness

Vivid, internally generated phenomenology occurring during REM sleep; sensory input is largely absent, yet the experience feels real.
 Deactivation of dorsolateral prefrontal cortex, hyper‑activation of limbic structures (amygdala, hippocampus). Reduced sensory gating.
All mammals capable of REM sleep (humans, cats, rats).
Narrative scenes, emotions, sense of agency (often distorted).
Polysomnography shows characteristic EEG patterns; lucid‑dreamers can signal via eye movements.
Why does the brain generate such rich worlds without external input?

Lucid‑dream consciousness

Dream state combined with meta‑awareness that one is dreaming; allows volitional control.
 Reactivation of frontoparietal network (especially dorsolateral PFC) within REM.
## Humans (trained lucid‑dreamers).

Same phenomenology as regular dreams plus reflective insight and control.
Increased gamma activity in frontal regions; subjects can communicate via pre‑arranged eye‑movement codes.
## How does the brain reinstate meta‑cognition during REM?

Locked‑in consciousness (LIS)

Persistent phenomenal experience despite near‑total motor paralysis; patients can communicate only via eye‑movement or brain‑computer interfaces.
 Intact cortical networks (global workspace, frontoparietal) with disrupted corticospinal output.
## Humans with brainstem stroke or ALS.

Full waking awareness, often with vivid inner life. fMRI shows typical task‑evoked activations; EEG shows event‑related potentials similar to healthy controls.
Ethical issues around assessing wishes; how to differentiate true awareness from covert reflexes.

Blindsight consciousness

Residual visual discrimination without accompanying visual phenomenology; patients deny seeing but can guess location/orientation above chance.
 Damage to primary visual cortex (V1) with spared extrastriate pathways (e.g., superior colliculus).
Humans with V1 lesions; some animals with similar lesions.
No subjective visual experience, yet behaviorally aware.
Forced‑choice tasks reveal above‑chance performance; neuroimaging shows activation in dorsal stream.
Demonstrates dissociation between access and phenomenal consciousness; raises questions about the minimal substrate for experience.

Split‑brain consciousness

Two semi‑independent streams of awareness after surgical severance of the corpus callosum; each hemisphere can act autonomously.
 Disconnection of inter‑hemispheric communication; each hemisphere retains its own global workspace.
Humans post‑callosotomy; some marsupials naturally have less inter‑hemispheric connectivity.
Patients may name objects seen only by the left visual field (right hemisphere) with no verbal report, yet can draw them with the left hand.
Behavioral split‑tasks, EEG showing independent oscillatory patterns.
## To what extent are the two selves truly separate?

Altered‑state consciousness

Phenomenology that deviates markedly from ordinary waking awareness due to pharmacology, meditation, or anesthesia.
 Varied: psychedelics increase thalamocortical entropy; meditation enhances frontoparietal coherence; anesthesia suppresses global workspace ignition.
Humans (psychedelic trials, meditation practitioners, anesthetized patients).
Visual hallucinations, ego dissolution, timelessness, profound unity, or complete loss of content. fMRI shows reduced modular segregation under psychedelics; EEG shows increased broadband power; meditation shows increased gamma synchrony.
How do different neurochemical routes converge on similar phenomenological reports? What is the core of consciousness that persists across states?

How the Pieces Fit Together Bottom‑up building blocks
(integrated information, recurrent processing, predictive coding) create a rich, differentiated neural state space.
## Middle‑level mechanisms

(global workspace broadcasting, higher‑order thought) select a subset of that state space for global availability
the moment we can report or act on it.
## Top‑down modulators

(precision weighting in predictive coding, meta‑cognitive monitoring in HOT) shape what gets broadcast and how it is experienced.
Species‑specific configurations determine which of these mechanisms are present, how they are wired, and thus which form of consciousness emerges (primary vs. reflective, collective, etc.).
## Contextual states

(dreaming, anesthesia, psychedelia) illustrate that the same circuitry can be re‑configured, producing dramatically different phenomenology while still obeying the same computational principles.

Quick Reference Cheat‑Sheet (One‑Line Summary)

Category Core Idea

Φ (IIT)

Maximal causal integration ↔ consciousness.

GWT

Broadcast of a winner to a global blackboard.

HOT

A thought about a mental state makes that state conscious.

Predictive Coding

Best Bayesian prediction of sensory input = experience.

RPT

Sustained local reverberation = awareness.

Primary

Sensory awareness without self‑report.

Reflective

Self‑aware, introspective cognition.

Collective

Distributed, emergent group‑level informational state.

Artificial

Engineered system meeting the above functional criteria.

Dream

Internally generated, vivid phenomenology during REM.

Lucid Dream

Dream + meta‑awareness.

Locked‑in

Full awareness despite motor paralysis.

Blindsight

Behavioural discrimination without phenomenology.

Split‑brain

Two semi‑independent conscious streams.

Altered‑state

Pharmacologically or medially induced phenomenology shift.

Suggested Reading (for deeper dives)

Theory Classic Sources

Integrated Information Theory Tononi, Integrated Information Theory (2012); Oizumi et

al., J. Cogn. Neurosci.
(2014).

Global Workspace Theory Baars, A Cognitive Theory of Consciousness (1997); Dehaene & Changeux, Trends Cogn. Sci.
(2011).

Higher‑Order Thought Rosenthal, Consciousness and Thought (2005); Lau & Rosenthal, Trends Cogn. Sci.
(2011).

Predictive Processing Friston, Nature Reviews Neuroscience (2010); Clark, Behav. Brain Sci.
(2013).

Recurrent Processing Theory Lamme, Trends Cogn. Sci.
(2006); VanRullen, Nat. Rev. Neurosci.
(2016).

Dream & Lucid Dream Hobson & Pace‑Schott, Nat. Rev. Neurosci.
(2002); LaBerge, Exploring the World of Lucid Dreaming (1990).

Locked‑in & Blindsight Owen et

al., Science (2006); Weiskrantz, Blindsight (1997).

Split‑brain Gazzaniga, The Split Brain (2005).

Altered States Carhart‑Harris & Friston, Neuron (2019); Lutz et

al., Trends Cogn. Sci.
(2007).

## Bottom Line

Consciousness appears to require a combination of integration, global broadcasting, and meta‑representational monitoring, implemented through recurrent, predictive, and hierarchical neural dynamics.
Different organisms (and even artificial systems) instantiate subsets of these mechanisms, leading to a spectrum ranging from basic perceptual awareness to fully reflective, self‑narrating minds.
Contextual states (dreams, anesthesia, psychedelics) demonstrate that the same hardware can be re‑wired, producing qualitatively distinct experiences while still respecting the underlying computational principles.
Feel free to ask for deeper detail on any single sub‑component, a specific species form, or how to map these ideas onto a concrete AI architecture!