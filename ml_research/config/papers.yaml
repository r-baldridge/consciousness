# ML Research Papers Reference Database
# Comprehensive catalog of landmark papers in machine learning and AI

papers:
  # ============================================================================
  # FOUNDATIONAL PAPERS (1940s-1960s)
  # ============================================================================

  mcculloch_pitts_1943:
    title: "A Logical Calculus of Ideas Immanent in Nervous Activity"
    authors: ["Warren McCulloch", "Walter Pitts"]
    year: 1943
    venue: "Bulletin of Mathematical Biophysics"
    volume: 5
    pages: "115-133"
    url: "https://doi.org/10.1007/BF02478259"
    citations: 25000
    methods: ["mcculloch_pitts"]
    tags: ["foundational", "neuroscience", "logic"]
    abstract_summary: "First mathematical model treating neurons as logical units"

  hebb_1949:
    title: "The Organization of Behavior: A Neuropsychological Theory"
    authors: ["Donald Hebb"]
    year: 1949
    venue: "Wiley"
    type: "book"
    url: "https://en.wikipedia.org/wiki/The_Organization_of_Behavior"
    citations: 30000
    methods: ["hebbian_learning"]
    tags: ["foundational", "neuroscience", "learning"]
    abstract_summary: "Introduced Hebbian learning rule for synaptic plasticity"

  rosenblatt_1958:
    title: "The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain"
    authors: ["Frank Rosenblatt"]
    year: 1958
    venue: "Psychological Review"
    volume: 65
    pages: "386-408"
    url: "https://doi.org/10.1037/h0042519"
    citations: 15000
    methods: ["perceptron"]
    tags: ["foundational", "classifier", "learning"]
    abstract_summary: "First trainable neural network model"

  widrow_hoff_1960:
    title: "Adaptive Switching Circuits"
    authors: ["Bernard Widrow", "Marcian Hoff"]
    year: 1960
    venue: "IRE WESCON Convention Record"
    pages: "96-104"
    url: "https://isl.stanford.edu/~widrow/papers/c1960adaptiveswitching.pdf"
    citations: 8000
    methods: ["adaline"]
    tags: ["foundational", "adaptive", "delta_rule"]
    abstract_summary: "Introduced ADALINE and the delta learning rule"

  minsky_papert_1969:
    title: "Perceptrons: An Introduction to Computational Geometry"
    authors: ["Marvin Minsky", "Seymour Papert"]
    year: 1969
    venue: "MIT Press"
    type: "book"
    url: "https://mitpress.mit.edu/9780262630221/perceptrons/"
    citations: 12000
    methods: ["perceptron"]
    tags: ["foundational", "limitations", "xor_problem"]
    abstract_summary: "Analysis of perceptron limitations, causing AI winter"

  # ============================================================================
  # CLASSICAL PAPERS (1970s-1990s)
  # ============================================================================

  fukushima_1980:
    title: "Neocognitron: A Self-organizing Neural Network Model for a Mechanism of Pattern Recognition Unaffected by Shift in Position"
    authors: ["Kunihiko Fukushima"]
    year: 1980
    venue: "Biological Cybernetics"
    volume: 36
    pages: "193-202"
    url: "https://doi.org/10.1007/BF00344251"
    citations: 5000
    methods: ["neocognitron"]
    tags: ["vision", "hierarchical", "biological"]
    abstract_summary: "Precursor to CNNs with hierarchical feature extraction"

  hopfield_1982:
    title: "Neural Networks and Physical Systems with Emergent Collective Computational Abilities"
    authors: ["John Hopfield"]
    year: 1982
    venue: "Proceedings of the National Academy of Sciences"
    volume: 79
    pages: "2554-2558"
    url: "https://doi.org/10.1073/pnas.79.8.2554"
    citations: 20000
    methods: ["hopfield_network"]
    tags: ["associative_memory", "energy_based", "physics"]
    abstract_summary: "Energy-based neural network for associative memory"

  hinton_sejnowski_1985:
    title: "A Learning Algorithm for Boltzmann Machines"
    authors: ["Geoffrey Hinton", "Terrence Sejnowski"]
    year: 1985
    venue: "Cognitive Science"
    volume: 9
    pages: "147-169"
    url: "https://doi.org/10.1207/s15516709cog0901_7"
    citations: 8000
    methods: ["boltzmann_machine"]
    tags: ["generative", "stochastic", "energy_based"]
    abstract_summary: "Stochastic neural network with probabilistic learning"

  rumelhart_hinton_williams_1986:
    title: "Learning Representations by Back-propagating Errors"
    authors: ["David Rumelhart", "Geoffrey Hinton", "Ronald Williams"]
    year: 1986
    venue: "Nature"
    volume: 323
    pages: "533-536"
    url: "https://doi.org/10.1038/323533a0"
    citations: 45000
    methods: ["backpropagation", "mlp"]
    tags: ["learning", "gradient", "fundamental"]
    abstract_summary: "Popularized backpropagation for training neural networks"

  lecun_1989:
    title: "Backpropagation Applied to Handwritten Zip Code Recognition"
    authors: ["Yann LeCun", "Bernhard Boser", "John Denker", "Donnie Henderson", "Richard Howard", "Wayne Hubbard", "Lawrence Jackel"]
    year: 1989
    venue: "Neural Computation"
    volume: 1
    pages: "541-551"
    url: "https://doi.org/10.1162/neco.1989.1.4.541"
    citations: 12000
    methods: ["lenet"]
    tags: ["cnn", "vision", "practical"]
    abstract_summary: "First successful application of CNNs to real-world task"

  lecun_1998:
    title: "Gradient-Based Learning Applied to Document Recognition"
    authors: ["Yann LeCun", "Leon Bottou", "Yoshua Bengio", "Patrick Haffner"]
    year: 1998
    venue: "Proceedings of the IEEE"
    volume: 86
    pages: "2278-2324"
    url: "https://doi.org/10.1109/5.726791"
    citations: 35000
    methods: ["lenet"]
    tags: ["cnn", "vision", "comprehensive"]
    abstract_summary: "Comprehensive CNN paper with LeNet-5 architecture"

  cortes_vapnik_1995:
    title: "Support-Vector Networks"
    authors: ["Corinna Cortes", "Vladimir Vapnik"]
    year: 1995
    venue: "Machine Learning"
    volume: 20
    pages: "273-297"
    url: "https://doi.org/10.1007/BF00994018"
    citations: 50000
    methods: ["svm"]
    tags: ["kernel", "classification", "theory"]
    abstract_summary: "Introduced support vector machines for classification"

  hochreiter_schmidhuber_1997:
    title: "Long Short-Term Memory"
    authors: ["Sepp Hochreiter", "Jurgen Schmidhuber"]
    year: 1997
    venue: "Neural Computation"
    volume: 9
    pages: "1735-1780"
    url: "https://doi.org/10.1162/neco.1997.9.8.1735"
    citations: 70000
    methods: ["lstm"]
    tags: ["recurrent", "sequence", "memory"]
    abstract_summary: "Gated memory cells solving vanishing gradient problem"

  breiman_2001:
    title: "Random Forests"
    authors: ["Leo Breiman"]
    year: 2001
    venue: "Machine Learning"
    volume: 45
    pages: "5-32"
    url: "https://doi.org/10.1023/A:1010933404324"
    citations: 90000
    methods: ["random_forest"]
    tags: ["ensemble", "trees", "practical"]
    abstract_summary: "Ensemble of randomized decision trees"

  hinton_2002:
    title: "Training Products of Experts by Minimizing Contrastive Divergence"
    authors: ["Geoffrey Hinton"]
    year: 2002
    venue: "Neural Computation"
    volume: 14
    pages: "1771-1800"
    url: "https://doi.org/10.1162/089976602760128018"
    citations: 8000
    methods: ["rbm"]
    tags: ["generative", "training", "energy_based"]
    abstract_summary: "Efficient training for restricted Boltzmann machines"

  # ============================================================================
  # DEEP LEARNING PAPERS (2006-2014)
  # ============================================================================

  hinton_salakhutdinov_2006:
    title: "Reducing the Dimensionality of Data with Neural Networks"
    authors: ["Geoffrey Hinton", "Ruslan Salakhutdinov"]
    year: 2006
    venue: "Science"
    volume: 313
    pages: "504-507"
    url: "https://doi.org/10.1126/science.1127647"
    citations: 18000
    methods: ["autoencoder", "deep_belief_network"]
    tags: ["pretraining", "dimensionality", "renaissance"]
    abstract_summary: "Deep autoencoders via layer-wise pretraining"

  hinton_osindero_teh_2006:
    title: "A Fast Learning Algorithm for Deep Belief Nets"
    authors: ["Geoffrey Hinton", "Simon Osindero", "Yee-Whye Teh"]
    year: 2006
    venue: "Neural Computation"
    volume: 18
    pages: "1527-1554"
    url: "https://doi.org/10.1162/neco.2006.18.7.1527"
    citations: 12000
    methods: ["deep_belief_network"]
    tags: ["pretraining", "generative", "deep"]
    abstract_summary: "Greedy layer-wise training for deep networks"

  krizhevsky_2012:
    title: "ImageNet Classification with Deep Convolutional Neural Networks"
    authors: ["Alex Krizhevsky", "Ilya Sutskever", "Geoffrey Hinton"]
    year: 2012
    venue: "NeurIPS"
    pages: "1097-1105"
    url: "https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks"
    citations: 120000
    methods: ["alexnet", "dropout"]
    tags: ["vision", "gpu", "breakthrough"]
    abstract_summary: "AlexNet winning ImageNet, starting deep learning revolution"

  dropout_2014:
    title: "Dropout: A Simple Way to Prevent Neural Networks from Overfitting"
    authors: ["Nitish Srivastava", "Geoffrey Hinton", "Alex Krizhevsky", "Ilya Sutskever", "Ruslan Salakhutdinov"]
    year: 2014
    venue: "Journal of Machine Learning Research"
    volume: 15
    pages: "1929-1958"
    url: "https://jmlr.org/papers/v15/srivastava14a.html"
    citations: 45000
    methods: ["dropout"]
    tags: ["regularization", "training", "simple"]
    abstract_summary: "Stochastic regularization technique for neural networks"

  mikolov_2013_word2vec:
    title: "Efficient Estimation of Word Representations in Vector Space"
    authors: ["Tomas Mikolov", "Kai Chen", "Greg Corrado", "Jeffrey Dean"]
    year: 2013
    venue: "ICLR Workshop"
    url: "https://arxiv.org/abs/1301.3781"
    citations: 35000
    methods: ["word2vec"]
    tags: ["nlp", "embeddings", "unsupervised"]
    abstract_summary: "Word2Vec embeddings with skip-gram and CBOW"

  mikolov_2013_distributed:
    title: "Distributed Representations of Words and Phrases and their Compositionality"
    authors: ["Tomas Mikolov", "Ilya Sutskever", "Kai Chen", "Greg Corrado", "Jeffrey Dean"]
    year: 2013
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/1310.4546"
    citations: 30000
    methods: ["word2vec"]
    tags: ["nlp", "embeddings", "negative_sampling"]
    abstract_summary: "Improved Word2Vec with negative sampling"

  kingma_welling_2013:
    title: "Auto-Encoding Variational Bayes"
    authors: ["Diederik Kingma", "Max Welling"]
    year: 2013
    venue: "ICLR"
    url: "https://arxiv.org/abs/1312.6114"
    citations: 25000
    methods: ["vae"]
    tags: ["generative", "variational", "latent"]
    abstract_summary: "Variational autoencoders with reparameterization trick"

  goodfellow_2014:
    title: "Generative Adversarial Nets"
    authors: ["Ian Goodfellow", "Jean Pouget-Abadie", "Mehdi Mirza", "Bing Xu", "David Warde-Farley", "Sherjil Ozair", "Aaron Courville", "Yoshua Bengio"]
    year: 2014
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/1406.2661"
    citations: 55000
    methods: ["gan"]
    tags: ["generative", "adversarial", "game_theory"]
    abstract_summary: "Adversarial training framework for generative models"

  sutskever_2014:
    title: "Sequence to Sequence Learning with Neural Networks"
    authors: ["Ilya Sutskever", "Oriol Vinyals", "Quoc V. Le"]
    year: 2014
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/1409.3215"
    citations: 25000
    methods: ["seq2seq"]
    tags: ["nlp", "translation", "encoder_decoder"]
    abstract_summary: "Encoder-decoder architecture for sequence transduction"

  bahdanau_2014:
    title: "Neural Machine Translation by Jointly Learning to Align and Translate"
    authors: ["Dzmitry Bahdanau", "Kyunghyun Cho", "Yoshua Bengio"]
    year: 2014
    venue: "ICLR"
    url: "https://arxiv.org/abs/1409.0473"
    citations: 35000
    methods: ["bahdanau_attention"]
    tags: ["attention", "nlp", "translation"]
    abstract_summary: "Attention mechanism for neural machine translation"

  cho_2014:
    title: "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation"
    authors: ["Kyunghyun Cho", "Bart van Merrienboer", "Caglar Gulcehre", "Dzmitry Bahdanau", "Fethi Bougares", "Holger Schwenk", "Yoshua Bengio"]
    year: 2014
    venue: "EMNLP"
    url: "https://arxiv.org/abs/1406.1078"
    citations: 20000
    methods: ["gru", "seq2seq"]
    tags: ["recurrent", "nlp", "encoder_decoder"]
    abstract_summary: "GRU architecture and encoder-decoder framework"

  kingma_ba_2014:
    title: "Adam: A Method for Stochastic Optimization"
    authors: ["Diederik Kingma", "Jimmy Ba"]
    year: 2014
    venue: "ICLR"
    url: "https://arxiv.org/abs/1412.6980"
    citations: 150000
    methods: ["adam"]
    tags: ["optimizer", "adaptive", "training"]
    abstract_summary: "Adaptive optimizer combining momentum and RMSprop"

  simonyan_zisserman_2014:
    title: "Very Deep Convolutional Networks for Large-Scale Image Recognition"
    authors: ["Karen Simonyan", "Andrew Zisserman"]
    year: 2014
    venue: "ICLR"
    url: "https://arxiv.org/abs/1409.1556"
    citations: 85000
    methods: ["vgg"]
    tags: ["vision", "deep", "simple"]
    abstract_summary: "VGGNet demonstrating depth with small filters"

  szegedy_2014:
    title: "Going Deeper with Convolutions"
    authors: ["Christian Szegedy", "Wei Liu", "Yangqing Jia", "Pierre Sermanet", "Scott Reed", "Dragomir Anguelov", "Dumitru Erhan", "Vincent Vanhoucke", "Andrew Rabinovich"]
    year: 2014
    venue: "CVPR"
    url: "https://arxiv.org/abs/1409.4842"
    citations: 40000
    methods: ["googlenet"]
    tags: ["vision", "inception", "efficient"]
    abstract_summary: "GoogLeNet with inception modules"

  # ============================================================================
  # MODERN DEEP LEARNING PAPERS (2015-2017)
  # ============================================================================

  he_2015:
    title: "Deep Residual Learning for Image Recognition"
    authors: ["Kaiming He", "Xiangyu Zhang", "Shaoqing Ren", "Jian Sun"]
    year: 2015
    venue: "CVPR"
    url: "https://arxiv.org/abs/1512.03385"
    citations: 180000
    methods: ["resnet"]
    tags: ["vision", "residual", "very_deep"]
    abstract_summary: "Skip connections enabling 100+ layer networks"

  ioffe_szegedy_2015:
    title: "Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift"
    authors: ["Sergey Ioffe", "Christian Szegedy"]
    year: 2015
    venue: "ICML"
    url: "https://arxiv.org/abs/1502.03167"
    citations: 50000
    methods: ["batch_normalization"]
    tags: ["normalization", "training", "acceleration"]
    abstract_summary: "Normalizing layer inputs for faster training"

  shazeer_2017:
    title: "Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer"
    authors: ["Noam Shazeer", "Azalia Mirhoseini", "Krzysztof Maziarz", "Andy Davis", "Quoc Le", "Geoffrey Hinton", "Jeff Dean"]
    year: 2017
    venue: "ICLR"
    url: "https://arxiv.org/abs/1701.06538"
    citations: 2500
    methods: ["mixture_of_experts"]
    tags: ["sparse", "scaling", "conditional"]
    abstract_summary: "Mixture of experts for conditional computation"

  # ============================================================================
  # TRANSFORMER ERA PAPERS (2017-2020)
  # ============================================================================

  attention_is_all_you_need:
    title: "Attention Is All You Need"
    authors: ["Ashish Vaswani", "Noam Shazeer", "Niki Parmar", "Jakob Uszkoreit", "Llion Jones", "Aidan N. Gomez", "Lukasz Kaiser", "Illia Polosukhin"]
    year: 2017
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/1706.03762"
    citations: 100000
    methods: ["transformer", "self_attention", "multi_head_attention"]
    tags: ["attention", "nlp", "paradigm_shift"]
    abstract_summary: "Self-attention replacing recurrence entirely"

  devlin_2018:
    title: "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding"
    authors: ["Jacob Devlin", "Ming-Wei Chang", "Kenton Lee", "Kristina Toutanova"]
    year: 2018
    venue: "NAACL"
    url: "https://arxiv.org/abs/1810.04805"
    citations: 80000
    methods: ["bert"]
    tags: ["nlp", "pretraining", "bidirectional"]
    abstract_summary: "Bidirectional pretraining with masked language modeling"

  radford_2018:
    title: "Improving Language Understanding by Generative Pre-Training"
    authors: ["Alec Radford", "Karthik Narasimhan", "Tim Salimans", "Ilya Sutskever"]
    year: 2018
    venue: "OpenAI Technical Report"
    url: "https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"
    citations: 10000
    methods: ["gpt"]
    tags: ["nlp", "pretraining", "autoregressive"]
    abstract_summary: "GPT: Generative pretraining for language understanding"

  radford_2019:
    title: "Language Models are Unsupervised Multitask Learners"
    authors: ["Alec Radford", "Jeffrey Wu", "Rewon Child", "David Luan", "Dario Amodei", "Ilya Sutskever"]
    year: 2019
    venue: "OpenAI Technical Report"
    url: "https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"
    citations: 15000
    methods: ["gpt2"]
    tags: ["nlp", "zero_shot", "scaling"]
    abstract_summary: "GPT-2 demonstrating zero-shot capabilities"

  dai_2019:
    title: "Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context"
    authors: ["Zihang Dai", "Zhilin Yang", "Yiming Yang", "Jaime Carbonell", "Quoc V. Le", "Ruslan Salakhutdinov"]
    year: 2019
    venue: "ACL"
    url: "https://arxiv.org/abs/1901.02860"
    citations: 3000
    methods: ["transformer_xl"]
    tags: ["nlp", "long_context", "recurrence"]
    abstract_summary: "Segment-level recurrence for longer contexts"

  yang_2019:
    title: "XLNet: Generalized Autoregressive Pretraining for Language Understanding"
    authors: ["Zhilin Yang", "Zihang Dai", "Yiming Yang", "Jaime Carbonell", "Ruslan Salakhutdinov", "Quoc V. Le"]
    year: 2019
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/1906.08237"
    citations: 8000
    methods: ["xlnet"]
    tags: ["nlp", "pretraining", "permutation"]
    abstract_summary: "Permutation language modeling combining AR and AE"

  tan_le_2019:
    title: "EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks"
    authors: ["Mingxing Tan", "Quoc V. Le"]
    year: 2019
    venue: "ICML"
    url: "https://arxiv.org/abs/1905.11946"
    citations: 15000
    methods: ["efficientnet"]
    tags: ["vision", "scaling", "efficient"]
    abstract_summary: "Compound scaling for efficient CNNs"

  brown_2020:
    title: "Language Models are Few-Shot Learners"
    authors: ["Tom Brown", "Benjamin Mann", "Nick Ryder", "Melanie Subbiah", "Jared Kaplan", "Prafulla Dhariwal", "Arvind Neelakantan", "Pranav Shyam", "Girish Sastry", "Amanda Askell", "et al."]
    year: 2020
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/2005.14165"
    citations: 25000
    methods: ["gpt3"]
    tags: ["nlp", "few_shot", "emergent", "scaling"]
    abstract_summary: "GPT-3 with emergent few-shot learning abilities"

  dosovitskiy_2020:
    title: "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
    authors: ["Alexey Dosovitskiy", "Lucas Beyer", "Alexander Kolesnikov", "Dirk Weissenborn", "Xiaohua Zhai", "Thomas Unterthiner", "Mostafa Dehghani", "Matthias Minderer", "Georg Heigold", "Sylvain Gelly", "Jakob Uszkoreit", "Neil Houlsby"]
    year: 2020
    venue: "ICLR"
    url: "https://arxiv.org/abs/2010.11929"
    citations: 20000
    methods: ["vit"]
    tags: ["vision", "transformer", "patches"]
    abstract_summary: "Vision Transformer for image classification"

  ho_2020:
    title: "Denoising Diffusion Probabilistic Models"
    authors: ["Jonathan Ho", "Ajay Jain", "Pieter Abbeel"]
    year: 2020
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/2006.11239"
    citations: 10000
    methods: ["diffusion"]
    tags: ["generative", "diffusion", "denoising"]
    abstract_summary: "Diffusion models for high-quality generation"

  # ============================================================================
  # FOUNDATION MODEL PAPERS (2021-Present)
  # ============================================================================

  radford_2021:
    title: "Learning Transferable Visual Models From Natural Language Supervision"
    authors: ["Alec Radford", "Jong Wook Kim", "Chris Hallacy", "Aditya Ramesh", "Gabriel Goh", "Sandhini Agarwal", "Girish Sastry", "Amanda Askell", "Pamela Mishkin", "Jack Clark", "Gretchen Krueger", "Ilya Sutskever"]
    year: 2021
    venue: "ICML"
    url: "https://arxiv.org/abs/2103.00020"
    citations: 15000
    methods: ["clip"]
    tags: ["multimodal", "contrastive", "zero_shot"]
    abstract_summary: "CLIP: Contrastive language-image pretraining"

  ramesh_2021:
    title: "Zero-Shot Text-to-Image Generation"
    authors: ["Aditya Ramesh", "Mikhail Pavlov", "Gabriel Goh", "Scott Gray", "Chelsea Voss", "Alec Radford", "Mark Chen", "Ilya Sutskever"]
    year: 2021
    venue: "ICML"
    url: "https://arxiv.org/abs/2102.12092"
    citations: 5000
    methods: ["dalle"]
    tags: ["generative", "multimodal", "text_to_image"]
    abstract_summary: "DALL-E: Text-to-image generation"

  hu_2021:
    title: "LoRA: Low-Rank Adaptation of Large Language Models"
    authors: ["Edward Hu", "Yelong Shen", "Phillip Wallis", "Zeyuan Allen-Zhu", "Yuanzhi Li", "Shean Wang", "Lu Wang", "Weizhu Chen"]
    year: 2021
    venue: "ICLR"
    url: "https://arxiv.org/abs/2106.09685"
    citations: 8000
    methods: ["lora"]
    tags: ["fine_tuning", "efficient", "adaptation"]
    abstract_summary: "Parameter-efficient fine-tuning via low-rank matrices"

  rombach_2022:
    title: "High-Resolution Image Synthesis with Latent Diffusion Models"
    authors: ["Robin Rombach", "Andreas Blattmann", "Dominik Lorenz", "Patrick Esser", "Bjorn Ommer"]
    year: 2022
    venue: "CVPR"
    url: "https://arxiv.org/abs/2112.10752"
    citations: 8000
    methods: ["stable_diffusion"]
    tags: ["generative", "diffusion", "latent"]
    abstract_summary: "Latent diffusion for efficient high-res generation"

  ouyang_2022:
    title: "Training language models to follow instructions with human feedback"
    authors: ["Long Ouyang", "Jeff Wu", "Xu Jiang", "Diogo Almeida", "Carroll Wainwright", "Pamela Mishkin", "Chong Zhang", "Sandhini Agarwal", "Katarina Slama", "Alex Ray", "et al."]
    year: 2022
    venue: "NeurIPS"
    url: "https://arxiv.org/abs/2203.02155"
    citations: 5000
    methods: ["chatgpt"]
    tags: ["rlhf", "alignment", "instruction"]
    abstract_summary: "InstructGPT: RLHF for instruction following"

  openai_2023:
    title: "GPT-4 Technical Report"
    authors: ["OpenAI"]
    year: 2023
    venue: "arXiv"
    url: "https://arxiv.org/abs/2303.08774"
    citations: 5000
    methods: ["gpt4"]
    tags: ["multimodal", "large_scale", "capabilities"]
    abstract_summary: "GPT-4 multimodal model capabilities"

  touvron_2023:
    title: "LLaMA: Open and Efficient Foundation Language Models"
    authors: ["Hugo Touvron", "Thibaut Lavril", "Gautier Izacard", "Xavier Martinet", "Marie-Anne Lachaux", "Timothee Lacroix", "Baptiste Roziere", "Naman Goyal", "Eric Hambro", "Faisal Azhar", "Aurelien Rodriguez", "Armand Joulin", "Edouard Grave", "Guillaume Lample"]
    year: 2023
    venue: "arXiv"
    url: "https://arxiv.org/abs/2302.13971"
    citations: 3000
    methods: ["llama"]
    tags: ["open_source", "efficient", "foundation"]
    abstract_summary: "LLaMA: Efficient open foundation models"

  gu_dao_2023:
    title: "Mamba: Linear-Time Sequence Modeling with Selective State Spaces"
    authors: ["Albert Gu", "Tri Dao"]
    year: 2023
    venue: "arXiv"
    url: "https://arxiv.org/abs/2312.00752"
    citations: 500
    methods: ["mamba"]
    tags: ["ssm", "efficient", "sequence"]
    abstract_summary: "Mamba: Selective state space alternative to transformers"

# Metadata
metadata:
  version: "1.0.0"
  last_updated: "2024-01-19"
  total_papers: 45
  venues:
    - NeurIPS
    - ICML
    - ICLR
    - CVPR
    - ACL
    - NAACL
    - EMNLP
    - Nature
    - Science
    - arXiv
  citation_notes: "Citation counts are approximate and change over time"
